name: Monitor Open PRs and Run Analysis

on:
  schedule:
    - cron: "0 */6 * * *"
  workflow_dispatch:

permissions:
  actions: write
  contents: write
  pull-requests: read

# NEED TO BE CONFIGURED EACH PROJECT
env:
  UPSTREAM_REPO: "databricks/databricks-ai-bridge"
  BRANCH: "main"
  RUNNER_DISPATCH_TIMEOUT: 7200 # 2 hours
  FILTER_DISPATCH_TIMEOUT: 1800 # 30 minutes
  MAX_CONCURRENT: 1

jobs:
  monitor-open-prs:
    runs-on: ubuntu-latest

    steps:
      # --------------------------------------------------------------------
      # STEP 1 — FETCH OPEN PRs FROM UPSTREAM VIA GITHUB API
      # --------------------------------------------------------------------
      - name: Fetch open PRs and merge bases from upstream
        id: fetch-prs
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail

          echo "Fetching open PRs from upstream ${UPSTREAM_REPO}..."

          # List all open PRs from the upstream repository
          prs_json="[]"
          page=1
          per_page=100
          while true; do
            batch=$(curl -s -H "Authorization: token $GH_TOKEN" \
              "https://api.github.com/repos/${UPSTREAM_REPO}/pulls?state=open&per_page=${per_page}&page=${page}")
            count=$(echo "$batch" | jq 'length')
            [[ "$count" -eq 0 ]] && break
            prs_json=$(echo "$prs_json" "$batch" | jq -s 'add')
            [[ "$count" -lt "$per_page" ]] && break
            page=$((page + 1))
          done

          pr_count=$(echo "$prs_json" | jq 'length')
          echo "Found $pr_count open PR(s) in upstream."

          if [[ "$pr_count" -eq 0 ]]; then
            echo '[]' > prs_to_analyze.json
            echo "pr_count=0" >> $GITHUB_OUTPUT
            exit 0
          fi

          repo_name=$(echo "${GITHUB_REPOSITORY}" | cut -d'/' -f2)
          results="[]"
          base_ref="${BRANCH}"

          for idx in $(seq 0 $((pr_count - 1))); do
            head_repo=$(echo "$prs_json" | jq -r ".[$idx].head.repo.full_name")

            # Only process PRs whose head branch is in the upstream repo (skip fork PRs)
            if [[ "$head_repo" != "$UPSTREAM_REPO" ]]; then
              pr_num=$(echo "$prs_json" | jq -r ".[$idx].number")
              echo "Skipping PR #${pr_num} (head from fork: ${head_repo})"
              continue
            fi

            head_sha=$(echo "$prs_json" | jq -r ".[$idx].head.sha")
            pr_num=$(echo "$prs_json" | jq -r ".[$idx].number")
            head_ref=$(echo "$prs_json" | jq -r ".[$idx].head.ref")

            # Get merge base (commit where branch diverged from main) via Compare API on upstream
            compare=$(curl -s -H "Authorization: token $GH_TOKEN" \
              "https://api.github.com/repos/${UPSTREAM_REPO}/compare/${base_ref}...${head_sha}")

            merge_base_sha=$(echo "$compare" | jq -r '.merge_base_commit.sha // empty')
            if [[ -z "$merge_base_sha" ]] || [[ "$merge_base_sha" == "null" ]]; then
              echo "Skipping PR #${pr_num}: could not get merge base"
              continue
            fi

            # Only include PRs that touch at least one Python file
            files=$(echo "$compare" | jq -r '.files[]?.filename // empty')
            has_py=false
            if [[ -n "$files" ]]; then
              while IFS= read -r f; do
                [[ -z "$f" ]] && continue
                if [[ "$f" == *.py ]]; then has_py=true; break; fi
              done <<< "$files"
            fi
            if ! $has_py; then
              echo "Skipping PR #${pr_num}: no Python files changed"
              continue
            fi

            echo "PR #${pr_num} head=${head_sha} merge_base=${merge_base_sha} (branch ${head_ref})"
            entry=$(jq -n \
              --arg pr "$pr_num" \
              --arg head "$head_sha" \
              --arg base "$merge_base_sha" \
              --arg ref "$head_ref" \
              '{pr_number: $pr, head_sha: $head, merge_base_sha: $base, head_ref: $ref}')
            results=$(echo "$results" | jq --argjson e "$entry" '. + [$e]')
          done

          echo "$results" > prs_to_analyze.json
          count=$(echo "$results" | jq 'length')
          echo "pr_count=$count" >> $GITHUB_OUTPUT
          echo "PRs to analyze: $count"

      # --------------------------------------------------------------------
      # STEP 2 — FETCH PR HEADS FROM UPSTREAM INTO CURRENT REPO
      # (So run-analysis can checkout those commits in this repo)
      # --------------------------------------------------------------------
      - name: Fetch upstream PR refs and push into current repo
        if: steps.fetch-prs.outputs.pr_count != '0'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail

          git clone --no-tags "https://x-access-token:${GH_TOKEN}@github.com/${GITHUB_REPOSITORY}.git" push-repo
          cd push-repo
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          git remote add upstream "https://github.com/${UPSTREAM_REPO}.git" || true
          git fetch upstream --no-tags

          for idx in $(seq 0 $(($(jq 'length' ../prs_to_analyze.json) - 1))); do
            pr_num=$(jq -r ".[$idx].pr_number" ../prs_to_analyze.json)
            head_sha=$(jq -r ".[$idx].head_sha" ../prs_to_analyze.json)
            echo "Fetching upstream PR #${pr_num} (${head_sha}) into current repo..."
            git fetch upstream "refs/pull/${pr_num}/head:pr-${pr_num}" || true
            git push origin "pr-${pr_num}" || true
          done

          cd ..
          rm -rf push-repo
          echo "PR head refs are now in current repo."

      # --------------------------------------------------------------------
      # STEP 3 — TRIGGER ANALYSIS WORKFLOWS FOR EACH PR BRANCH
      # --------------------------------------------------------------------
      - name: Run analysis workflows for PR branches
        if: steps.fetch-prs.outputs.pr_count != '0'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          BRANCH: ${{ env.BRANCH }}
        run: |
          set -euo pipefail

          pr_count=$(jq 'length' prs_to_analyze.json)
          [[ "$pr_count" -eq 0 ]] && { echo "No PRs to analyze."; exit 0; }

          repo_name=$(echo "${GITHUB_REPOSITORY}" | cut -d'/' -f2)
          MAX_CONCURRENT=${{ env.MAX_CONCURRENT }}
          RUNNER_DISPATCH_TIMEOUT=${{ env.RUNNER_DISPATCH_TIMEOUT }}

          # Collect PRs that need analysis (artifact not already present)
          declare -a heads_to_process=()
          declare -a artifacts_to_process=()
          mapfile -t head_shas < <(jq -r '.[].head_sha' prs_to_analyze.json)

          for head_sha in "${head_shas[@]}"; do
            artifact="continuous-analysis-results-${repo_name}-${head_sha}"

            artifact_exists=false
            page=1
            per_page=100
            while true; do
              response=$(curl -s -H "Authorization: token $GH_TOKEN" \
                "https://api.github.com/repos/${GITHUB_REPOSITORY}/actions/artifacts?per_page=${per_page}&page=${page}")
              artifact_names=$(echo "$response" | jq -r '.artifacts[].name')
              if echo "$artifact_names" | grep -q "^${artifact}"; then
                artifact_exists=true
                break
              fi
              [[ -z "$artifact_names" ]] || [[ $(echo "$artifact_names" | wc -l) -lt $per_page ]] && break
              page=$((page + 1))
            done

            if $artifact_exists; then
              echo " ✓ Artifact exists: ${artifact} - skip"
            else
              echo " ✗ Will analyze PR branch: ${head_sha}"
              heads_to_process+=("$head_sha")
              artifacts_to_process+=("$artifact")
            fi
          done

          total_to_process=${#heads_to_process[@]}
          if [[ $total_to_process -eq 0 ]]; then
            echo "All PR branches already have analysis artifacts. Skipping dispatch."
            exit 0
          fi

          echo "Dispatching analysis for ${total_to_process} PR head commit(s)..."

          for ((batch_start=0; batch_start<total_to_process; batch_start+=MAX_CONCURRENT)); do
            batch_end=$((batch_start + MAX_CONCURRENT))
            ((batch_end > total_to_process)) && batch_end=$total_to_process

            declare -a dispatched_heads=()
            declare -a dispatched_artifacts=()

            for ((i=batch_start; i<batch_end; i++)); do
              head_sha="${heads_to_process[$i]}"
              artifact="${artifacts_to_process[$i]}"
              echo "  Dispatching analysis for commit $head_sha"
              gh workflow run run-analysis.yml \
                --repo "${GITHUB_REPOSITORY}" \
                --ref "${BRANCH}" \
                --field commit="$head_sha" \
                --field dispatch_id=""
              dispatched_heads+=("$head_sha")
              dispatched_artifacts+=("$artifact")
            done

            echo "Waiting for batch artifacts (timeout ${RUNNER_DISPATCH_TIMEOUT}s)..."
            end_time=$(( $(date +%s) + RUNNER_DISPATCH_TIMEOUT ))
            declare -a done=()

            while [[ ${#done[@]} -lt ${#dispatched_heads[@]} && $(date +%s) -lt $end_time ]]; do
              names=$(curl -s -H "Authorization: token $GH_TOKEN" \
                "https://api.github.com/repos/${GITHUB_REPOSITORY}/actions/artifacts?per_page=100" \
                | jq -r '.artifacts[].name')
              for idx in "${!dispatched_heads[@]}"; do
                if [[ " ${done[@]} " =~ " ${dispatched_heads[$idx]} " ]]; then continue; fi
                if echo "$names" | grep -q "^${dispatched_artifacts[$idx]}"; then
                  echo "  ✓ Artifact: ${dispatched_artifacts[$idx]}"
                  done+=("${dispatched_heads[$idx]}")
                fi
              done
              [[ ${#done[@]} -lt ${#dispatched_heads[@]} ]] && sleep 60
            done

            if [[ ${#done[@]} -lt ${#dispatched_heads[@]} ]]; then
              echo "ERROR: Timeout waiting for analysis artifacts."
              exit 1
            fi
            echo "Batch completed."
          done

      # --------------------------------------------------------------------
      # STEP 4 — TRIGGER FILTER WORKFLOWS (DIVERGENCE = MERGE BASE)
      # --------------------------------------------------------------------
      - name: Run violation filter workflows for PRs
        if: steps.fetch-prs.outputs.pr_count != '0'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          BRANCH: ${{ env.BRANCH }}
        run: |
          set -euo pipefail

          FILTER_DISPATCH_TIMEOUT=${{ env.FILTER_DISPATCH_TIMEOUT }}
          repo_name=$(echo "${GITHUB_REPOSITORY}" | cut -d'/' -f2)

          echo "Running violation filters (current = PR head, previous = merge base)..."

          for idx in $(seq 0 $(($(jq 'length' prs_to_analyze.json) - 1))); do
            current=$(jq -r ".[$idx].head_sha" prs_to_analyze.json)
            previous=$(jq -r ".[$idx].merge_base_sha" prs_to_analyze.json)
            pr_num=$(jq -r ".[$idx].pr_number" prs_to_analyze.json)

            echo "Filter PR #${pr_num}: current=$current previous=$previous"

            artifact="continuous-analysis-future-filtered-results-${repo_name}-${current}"

            gh workflow run run-filter.yml \
              --repo "${GITHUB_REPOSITORY}" \
              --ref "${BRANCH}" \
              --field current_commit="$current" \
              --field previous_commit="$previous" \
              --field dispatch_id="" \
              --field skip_commits_pattern="0"

            end_time=$(( $(date +%s) + FILTER_DISPATCH_TIMEOUT ))
            created=false
            while ! $created && [[ $(date +%s) -lt $end_time ]]; do
              names=$(curl -s -H "Authorization: token $GH_TOKEN" \
                "https://api.github.com/repos/${GITHUB_REPOSITORY}/actions/artifacts?per_page=100" \
                | jq -r '.artifacts[].name')
              if echo "$names" | grep -q "^${artifact}"; then
                echo "  ✓ Filter artifact: ${artifact}"
                created=true
                break
              fi
              sleep 30
            done

            if ! $created; then
              echo "ERROR: Timeout waiting for filter artifact: ${artifact}"
              exit 1
            fi
          done

          echo "All PR violation filters completed."
